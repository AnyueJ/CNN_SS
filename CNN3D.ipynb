{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "import time\n",
    "from tensorflow.contrib.slim import fully_connected as fc\n",
    "from tensorflow.python.ops.parallel_for.gradients import jacobian\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import cv2\n",
    "import random\n",
    "import h5py\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'train.mat'\n",
    "arrays = {}\n",
    "f = h5py.File(filepath)\n",
    "for k, v in f.items():\n",
    "    arrays[k] = np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = arrays[\"train\"]\n",
    "np.save('train.npy',train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 192000)\n",
      "(800, 192000)\n",
      "(800, 192000)\n",
      "(1, 192000)\n",
      "(200, 192000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = sio.loadmat('test.mat')\n",
    "PHI_ALL = sio.loadmat('PHI_ALL.mat')\n",
    "LOGPERM_MEAN = sio.loadmat('logmean.mat')\n",
    "\n",
    "test = np.array(test[\"test\"]).transpose()\n",
    "PHI_ALL = np.array(PHI_ALL[\"PHI_ALL\"]).transpose()\n",
    "LOGPERM_MEAN = np.array(LOGPERM_MEAN[\"logmean\"]).transpose()\n",
    "input_dim = 192000\n",
    "num_sample = 4000\n",
    "totals = 8\n",
    "maxiter = 4\n",
    "kpers = 25\n",
    "totalk = totals*kpers\n",
    "PHIMIX = sio.loadmat('PHIMIX.mat')\n",
    "PHIMIX = np.array(PHIMIX[\"PHIMIX\"]).transpose()\n",
    "k=[25,25,25,25,25,25,25,25];\n",
    "n1=0\n",
    "n2=0\n",
    "PHI = np.zeros((np.sum(k),192000))\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(PHI_ALL.shape)\n",
    "print(LOGPERM_MEAN.shape)\n",
    "print(PHI.shape)\n",
    "for nf in range(totals):\n",
    "    n2 =k[nf]+n2\n",
    "    PHI[n1: n2] = PHI_ALL[nf*100:nf*100+k[nf]]\n",
    "    n1 = k[nf]+n1\n",
    "    \n",
    "k=[25,25,25,25,25,25,25,25];\n",
    "n1=0\n",
    "n2=0\n",
    "PHIn = np.zeros((np.sum(k),192000))\n",
    "for nf in range(totals):\n",
    "    n2 =k[nf]+n2\n",
    "    PHIn[n1: n2] = PHI_ALL[nf*100:nf*100+k[nf]]\n",
    "    n1 = k[nf]+n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "\n",
    "    def __init__(self, conv1n):\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        self.conv1n = conv1n\n",
    "        self.build()\n",
    "        self.sess = tf.InteractiveSession(config=config)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Build the netowrk and the loss functions\n",
    "    def build(self):\n",
    "        self.x = tf.placeholder(\n",
    "            name='x', dtype=tf.float32, shape=[None, input_dim])\n",
    "        self.labels = tf.placeholder(\n",
    "            name='labels', dtype=tf.int64, shape=[None, 8])\n",
    "        self.learning_rate = tf.placeholder(name = 'learning_rate',dtype = tf.float32,shape = None)\n",
    "        self.drate = tf.placeholder(name = 'drate',dtype = tf.float32,shape = None)\n",
    "        self.onehotgrad = tf.placeholder(name = 'onehotgrad',dtype = tf.float32,shape = [None,8])\n",
    "        self.l1c = tf.placeholder(name = 'l1c',dtype = tf.float32,shape = None)\n",
    "        self.l2c = tf.placeholder(name = 'l2c',dtype = tf.float32,shape = None)\n",
    "        inp0 = tf.nn.dropout(self.x,rate = self.drate)\n",
    "        inp = tf.reshape(inp0,[-1,40,120,40,1])\n",
    "        self.conv1 = tf.contrib.layers.conv3d(inp,self.conv1n,3,stride=1,\n",
    "                                 padding='Same',activation_fn=tf.nn.relu,scope = 'Conv1')\n",
    "        mp1 = tf.contrib.layers.avg_pool3d(self.conv1,[2,2,2])\n",
    "        d1 = tf.nn.dropout(mp1,rate = self.drate)\n",
    "        self.conv2 = tf.contrib.layers.conv3d(d1,self.conv1n*2,3,stride=1,\n",
    "                                 padding='Same',activation_fn=tf.nn.relu,scope = 'Conv2')\n",
    "        self.mp2 = tf.contrib.layers.avg_pool3d(self.conv2,[2,2,2])\n",
    "        d2 = tf.nn.dropout(self.mp2,rate = self.drate)\n",
    "        \n",
    "        self.conv3 = tf.contrib.layers.conv3d(d2,self.conv1n*4,2,stride=1,\n",
    "                                 padding='Same',activation_fn=tf.nn.relu,scope = 'Conv3')\n",
    "\n",
    "        self.mp3 = tf.contrib.layers.avg_pool3d(self.conv3,[2,2,2])\n",
    "        d3 = tf.nn.dropout(self.mp3,rate = self.drate)\n",
    "        self.conv4 = tf.contrib.layers.conv3d(d3,self.conv1n*8,2,stride=1,\n",
    "                                 padding='Same',activation_fn=tf.nn.relu,scope = 'Conv4')\n",
    "        \n",
    "        self.mp4 = tf.contrib.layers.max_pool3d(self.conv4,[2,2,2])\n",
    "        \n",
    "        print(self.mp4.shape)\n",
    "        flate1 = tf.reshape(self.mp4,[-1,2*7*2*self.conv1n*8])\n",
    "        self.logits =fc(flate1, 8, scope='FC1',activation_fn=None)\n",
    "        print(self.logits.shape)\n",
    "        print(self.labels.shape)\n",
    "        self.l2w = sum(tf.nn.l2_loss(var) for var in tf.trainable_variables() if not 'biases' in var.name)\n",
    "        self.l2b = sum(tf.nn.l2_loss(var) for var in tf.trainable_variables() if not 'weights' in var.name)\n",
    "        self.l1w = sum(tf.reduce_sum(tf.abs(var)) for var in tf.trainable_variables() if not 'biases' in var.name)\n",
    "        self.l1b = sum(tf.reduce_sum(tf.abs(var)) for var in tf.trainable_variables() if not 'weights' in var.name)\n",
    "        self.loss = tf.losses.softmax_cross_entropy(self.labels, self.logits)\n",
    "        #self.total_loss = self.loss\n",
    "        self.total_loss = self.loss  + self.l2c*self.l2w + self.l2c*self.l2b +self.l1c*self.l1w +self.l1c*self.l1b\n",
    "        self.train_op = tf.train.AdamOptimizer(\n",
    "            learning_rate=self.learning_rate).minimize(self.total_loss)\n",
    "        \n",
    "        self.losses = {\n",
    "            'loss': self.loss,\n",
    "            'total_loss': self.total_loss,\n",
    "            'L1':self.l1w,\n",
    "            'L2':self.l2w\n",
    "        }     \n",
    "        self.prob = tf.nn.softmax(self.logits)\n",
    "        self.correct = tf.equal(tf.argmax(self.prob,1), tf.argmax(self.labels, 1))\n",
    "        self.accuracy=tf.reduce_mean(tf.cast(self.correct, tf.float32))\n",
    "        self.y_c = tf.reduce_sum(tf.multiply(self.logits,self.onehotgrad)+tf.constant(1e-5),axis = 1)\n",
    "        self.grad = tf.gradients(self.y_c,self.mp2)[0]\n",
    "        \n",
    "        return\n",
    "\n",
    "    # Execute the forward and the backward pass\n",
    "    def run_single_step(self, x,labels,learning_rate,drate,l1c,l2c):\n",
    "        _, losses = self.sess.run(\n",
    "            [self.train_op, self.losses],\n",
    "            feed_dict={self.x: x,self.labels: labels, self.learning_rate:learning_rate,self.drate: drate\n",
    "                      ,self.l1c:l1c, self.l2c:l2c}\n",
    "        )\n",
    "        return losses\n",
    "\n",
    "    # x -> x_hat\n",
    "    def predictprob(self, x):\n",
    "        drate = 0\n",
    "        prob = self.sess.run(self.prob, feed_dict={self.x: x,self.drate: drate})\n",
    "        \n",
    "        return prob\n",
    "    def predictclass(self, x):\n",
    "        drate = 0\n",
    "        logits = self.sess.run(self.logits, feed_dict={self.x: x,self.drate: drate})\n",
    "        return pclass\n",
    "    def calaccuracy(self,x,label):\n",
    "        drate = 0\n",
    "        accuracy = self.sess.run(self.accuracy, feed_dict={self.x: x,self.labels:label,self.drate: drate})\n",
    "        \n",
    "        return accuracy\n",
    "    def caljacob(self,x,label,l1c,l2c):\n",
    "        drate = 0\n",
    "        jacob = self.sess.run(jacobian(self.total_loss,self.x), feed_dict={self.x:x,self.labels:label,self.drate:drate\n",
    "                                                                          ,self.l1c:l1c, self.l2c:l2c})\n",
    "        return jacob\n",
    "    def gradcam(self,x,nlabel):\n",
    "        drate = 0\n",
    "        onehotgrad = np.zeros((1,5))\n",
    "        onehotgrad[0,nlabel] = 1\n",
    "        gradcam = self.sess.run(self.grad,feed_dict={self.x:x,self.drate:drate,self.onehotgrad:onehotgrad})\n",
    "        return gradcam\n",
    "    def actmp2(self,x):\n",
    "        drate = 0\n",
    "        actmp2 = self.sess.run(self.mp4,feed_dict = {self.x:x,self.drate:drate})\n",
    "        return actmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(\n",
    "    model_object,convl1n,\n",
    "    learning_rate=1e-4, batch_size=64, train = train,test = test,\n",
    "    num_epochs=100, log_step=10, rnv = 1, rbv = 1, rnc = 0.5, rbc = 0.5,drate = 0,l1c = 0,l2c = 0,nscenario = 8,savename = \"tf_models/SPCNN.ckpt\"):\n",
    "    model = model_object(\n",
    "      convl1n\n",
    "    )\n",
    "    trainlabels = np.zeros((400*nscenario,nscenario))\n",
    "    testlabels = np.zeros((100*nscenario,nscenario))\n",
    "    for iscenario in range(nscenario):\n",
    "        trainlabels[iscenario*400:(iscenario+1)*400,iscenario] = 1\n",
    "    for iscenario in range(nscenario):\n",
    "        testlabels[iscenario*100:(iscenario+1)*100,iscenario] = 1\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        seq = np.random.permutation(400*nscenario)\n",
    "        traini = train[seq]\n",
    "        labelsi = trainlabels[seq]\n",
    "        for iter in range((400*nscenario) // batch_size):\n",
    "            batch = traini[iter*batch_size:(iter+1)*batch_size]\n",
    "            batchl = labelsi[iter*batch_size:(iter+1)*batch_size]\n",
    "            losses = model.run_single_step(batch,batchl,learning_rate,drate =drate,l1c = l1c, l2c = l2c)\n",
    "        end_time = time.time()\n",
    "        if epoch % log_step == 0:\n",
    "            acc = 0\n",
    "            for nset in range(16):\n",
    "                acc = acc + model.calaccuracy(train[nset*200:(nset+1)*200],trainlabels[nset*200:(nset+1)*200])\n",
    "            acc = acc/16\n",
    "            log_str = '[Epoch: {}] '.format(epoch)\n",
    "            log_str += 'Accuracy: {:.3f}, '.format(acc)\n",
    "            for k, v in losses.items():\n",
    "                log_str += '{}: {:.3f}, '.format(k, v)\n",
    "            log_str += '({:.3f}sec/epoch)'.format(end_time - start_time)\n",
    "            print(log_str)\n",
    "            acc = 0\n",
    "            for nset in range(16):\n",
    "                acc = acc + model.calaccuracy(test[nset*50:(nset+1)*50],testlabels[nset*50:(nset+1)*50])\n",
    "            acc = acc/16\n",
    "            log_str = 'Accuracy: {:.3f}, '.format(acc)\n",
    "            print(log_str)\n",
    "        if epoch % 50== 0:\n",
    "            learning_rate = learning_rate*0.95\n",
    "    saver = tf.train.Saver()\n",
    "    model_path = saver.save(model.sess, savename)\n",
    "    acc = 0\n",
    "    for nset in range(16):\n",
    "        acc = acc + model.calaccuracy(train[nset*200:(nset+1)*200],trainlabels[nset*200:(nset+1)*200])\n",
    "    acc = acc/16\n",
    "    log_str = '[Epoch: {}] '.format(epoch)\n",
    "    log_str += 'Accuracy: {:.3f}, '.format(acc)\n",
    "    for k, v in losses.items():\n",
    "        log_str += '{}: {:.3f}, '.format(k, v)\n",
    "    log_str += '({:.3f}sec/epoch)'.format(end_time - start_time)\n",
    "    print(log_str)\n",
    "    acc = 0\n",
    "    for nset in range(16):\n",
    "        acc = acc + model.calaccuracy(test[nset*50:(nset+1)*50],testlabels[nset*50:(nset+1)*50])\n",
    "    acc = acc/16\n",
    "    log_str = 'Accuracy: {:.3f}, '.format(acc)\n",
    "    print(log_str)\n",
    "    \n",
    "    print(\"Model saved in %s\" % model_path)\n",
    "    print('Done')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2, 7, 2, 16)\n",
      "(?, 8)\n",
      "(?, 8)\n",
      "[Epoch: 0] Accuracy: 0.865, loss: 0.461, total_loss: 0.464, L1: 367.747, L2: 19.482, (8.288sec/epoch)\n",
      "Accuracy: 0.862, \n",
      "[Epoch: 10] Accuracy: 1.000, loss: 0.000, total_loss: 0.003, L1: 377.417, L2: 21.066, (8.616sec/epoch)\n",
      "Accuracy: 1.000, \n",
      "[Epoch: 19] Accuracy: 1.000, loss: 0.000, total_loss: 0.002, L1: 370.303, L2: 20.474, (8.564sec/epoch)\n",
      "Accuracy: 1.000, \n",
      "Model saved in tf_models/CNN3D.ckpt\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "model = trainer(CNN, 2,num_epochs=20, learning_rate=5e-4, batch_size=50,\n",
    "                train = train,rnc = 2, rbc = 3,drate = 0, l1c = 0.000001, l2c = 0.0001,savename = \"tf_models/CNN3D.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alexa\\.conda\\envs\\tf_GPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(?, 2, 7, 2, 16)\n",
      "(?, 8)\n",
      "(?, 8)\n",
      "WARNING:tensorflow:From C:\\Users\\alexa\\.conda\\envs\\tf_GPU\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\alexa\\.conda\\envs\\tf_GPU\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\alexa\\.conda\\envs\\tf_GPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from tf_models/CNN3D.ckpt\n"
     ]
    }
   ],
   "source": [
    "model = CNN(2)\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(model.sess, \"tf_models/CNN3D.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
